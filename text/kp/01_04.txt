1.4 The shell
When the system prints the prompt $ and you type commands that get executed, it's not the kernel that is talking to you, but a go-between called the
command interpreter or shell. The shell is just an ordinary program like date
or who, although it can do some remarkable things. The fact that the shell sits
between you and the facilities of the kernel has real benefits, some of which
we'll talk about here. There are three main ones:
. Filename shorthands: you can pick up a whole set of filenames as arguments to a program by specifying a pattern for the names - the shell will
find the filenames that match your pattern.
. Input-output redirection: you can arrange for the output of any program to
go into a file instead of onto the terminal, and for the input to come from a
file instead of the terminal. Input and output can even be connected to
other programs.
. Personalizing the environlnent: you can define your own commands and
shorthands.
Filename shorthand
Let's begin with filename patterns. Suppose you're typing a large document
like a book. Logically this divides into many small pieces, like chapters and
perhaps sections. Physically it should be divided too, because it is cumbersome
to edit large files. Thus you should type the document as a number of files.
You might have separate files for each chapter, called ch 1, ch2, etc. Or, if
each chapter were broken into sections, you might create files called
ch 1 . 1
ch 1 . 2
ch 1 . 3
ch2.1
ch2.2
which is the organization we used for this book. With a systematic naming
convention, you can tell at a glance where a particular file fits into the whole.
What if you want to print the whole book? You could say
$ pr ch1. 1 ch1.2 ch1.3 ...
but you would soon get bored typing filenames and start to make mistakes.
This is where filename shorthand comes in. If you say
$ pr ch"*
the shell takes the * to mean "any string of characters," so ch* is a pattern
that matches all filenames in the current directory that begin with ch. The
shell creates the list, in alphabetical t order, and passes the list to pr. The pr
command never sees the *; the pattern match that the shell does in the current
directory generates a list of strings that are passed to pr.
The crucial point is that filename shorthand is not a property of the pr
command, but a service of the shell. Thus you can use it to generate a
sequence of filenames for any command. For example, to count the words in
the first chapter:
$ we ch 1 . "*
113 562 3200 ch 1 . 0
935 4081 22435 ch 1 . 1
974 4191 22756 ch 1 . 2
378 1561 8481 ch 1 . 3
1293 5298 28841 ch 1 . 4
33 194 1190 ch 1 . 5
75 323 2030 ch 1 . 6
3801 16210 88933 total
$
There is a program called echo that is especially valuable for experimenting with the meaning of the shorthand characters. As you might guess, echo
does nothing more than echo its arguments:
$ echo hello world
hello world
$
But the arguments can be generated by pattern-matching:
$ echo ch 1 . "*
lists the names of all the files in Chapter 1,
$ echo "*
lists all the filenames in the current directory in alphabetical order,
$ pr "*
prints all your files (in alphabetical order), and
t Again, the order is not strictly alphabetical, in that upper case letters come before lower case
letters. See ascii(7) for the ordering of the characters used in the sort.
$ rm *
removes ail files in your current directory. (You had better be very sure that's
what you wanted to say!)
The * is not limited to the last position in a filename - *'s can be anywhere and can occur several times. Thus
$ rm *.save
removes all files that end with . save.
Notice that the filenames are sorted alphabetically, which is not the same as
numerically. If your book has ten chapters, the order might not be what you
intended, since ch 10 comes before ch2:
$ echo *
ch 1 . 1 ch 1 . 2 . .. ch 10 . 1 ch 10 . 2 ... ch2. 1 ch2. 2 . . .
$
The * is not the only pattern-matching feature provided by the shell,
although it's by far the most frequently used. The pattern [...] matches any
of the characters inside the brackets. A range of consecutive letters or digits
can be abbreviated:
$ pr ch[12346789]*
$ pr ch[ 1-46-9]*
$ rm temp[a-z]
Print chapters 1,2,3,4,6,7,8,9 but not 5
Same thing
Remove any of tempa, ..., tempz that exist
The ? pattern matches any single character:
$ Is ?
$ Is -1 ch? 1
$ rm temp?
List files with single-character names
List ch 1 . 1 ch2. 1 ch3. 1, etc. but not ch 10 . 1
Remove files temp 1, ..., tempa, etc.
Note that the patterns match only existing filenames. In particular, you cannot
make up new filenames by using patterns. For example, if you want to expand
ch to chapter in each filename, you cannot do it this way:
$ mv ch.* chapter.*
Doesn't work!
because chapter. * matches no existing filenames.
Pattern characters like * can be used in pathnames as well as simple
filenames; the match is done for each component of the path that contains a
special character. Thus /usr /mary / * performs the match in /usr /mary,
and /usr / * / calendar generates a list of pathnames of all user calendar
files.
If you should ever have to turn off the special meaning of *, ?, etc.,
enclose the entire argument in single quotes, as in
$ Is '?'
You can also precede a special character with a backslash:
$ Is \?
(Remember that because ? is not the erase or line kill character, this backslash
is interpreted by the shell, not by the kernel.) Quoting is treated at length in
Chapter 3.
Exercise 1-4. What are the differences among these commands?
$ 1s junk $ echo junk
$ 1s / $ echo /
$ ls $ echo
$ ls '* $ echo '*
$ 1s ' '* ' $ echo ' '* '
0
Input-output redirection
Most of the commands we have seen so far produce output on the terminal;
some, like the editor, also take their input from the terminal. It is nearly
universal that the terminal can be replaced by a file for either or both of input
and output. As one example,
$ Is
makes a list of filenames on your terminal. But if you say
$ Is >filelist
that same list of filenames will be placed in the file filelist instead. The
symbol> means "put the output in the following file, rather than on the terminal." The file will be created if it doesn't already exist, or the previous contents overwritten if it does. Nothing is produced on your terminal. As
another example, you can combine several files into one by capturing the output of cat in a file:
$ cat f1 f2 f3 >temp
The symbol » operates much as > does, except that it means "add to the
end of." That is,
$ cat f1 f2 f3 »temp
copies the contents of f 1, f2 and f3 onto the end of whatever is already in
temp, instead of overwriting the existing contents. As with>, if temp doesn't
exist, it will be created initially empty for you.
In a similar way, the symbol < means to take the input for a program from
the following file, instead of from the terminal. Thus, you can prepare a lettel
in file 1 et, then send it to several people with
$ mail mary joe tom bob <let
In all of these examples, blanks are optional on either side of > or <, but ou
formatting is traditional.
Given the capability of redirecting output with >, it becomes possible to
combine commands to achieve effects not possible otherwise. For example, to
print an alphabetical list of users,
$ who :>temp
$ sort <temp
Since who prints one line of output per logged-on user, and we -1 counts lines
(suppressing the word and character counts), you can count users with
$ who >temp
$ we -1 <temp
You can count the files in the current directory with
$ 1s >temp
$ we -1 <temp
though this includes the filename temp itself in the count. You can print the
filenames in three columns with
$ 1s >temp
$ pr -3 <temp
And you can see if a particular user is logged on by combining who and grep:
$ who >temp
$ grep mary <temp
In all of these examples, as with filename pattern characters like *, it's
important to remember that the interpretation of > and < is being done by the
shell, not by the individual programs. Centralizing the facility in the shell
means that input and output redirection can be used with any program; the
program itself isn't aware that something unusual has happened.
This hrings up an important convention. The command
$ sort <temp
sorts the contents of the file temp, as does
$ sort temp
but there is a difference. Because the string <temp is interpreted by the shell,
sort does not see the filename temp as an argument; it instead sorts its standard input, which the shell has redirected so it comes from the file. The latter
example, however, passes the name temp as an argument to sort, which
reads the file and sorts it. sort can be given a list of filenames, as in
$ sort temp1 temp2 temp3
but if no filenames are given, it sorts its standard input. This is an essential
property of most commands: if no filenames are specified, the standard input is
processed. This means that you can simply type at commands to see how they
work. For example,
$ sort
ghi
abe
def
ctl-d
abc
def
ghi
$
In the next section, we will see how this principle is exploited.
Exercise 15. Explain why
$ 15 >ls.out
causes Is. out to be included in the list of names. 0
Exercise 1 6. Explain the output from
$ we temp >temp
If you misspell a command name, as in
$ woh >temp
what happens? 0
Pipes
All of the examples at the end of the previous section rely on the same
trick: putting the output of one program into the input of another via a temporary file. But the temporary file has no other purpose; indeed, it's clumsy to
have to use such a file. This observation leads to one of the fundamental contributions of the UNIX system, the idea of a pipe. A pipe is a way to connect
the output of one program to the input of another program without any tem-
porary file; a pipeline is a connection of two or more programs through pipes.
Let us revise some of the earlier examples to use pipes instead of temporaries. The vertical bar character : tells the shell to set up a pipeline:
$ who : sort
$ who : we -1
$ 1s : we -1
$ 1s : pr -3
$ who : grep mary
Print sorted list of users
Count users
Count files
3 -column list offilenames
Look for particular user
Any program that reads from the terminal can read from a pipe instead;
any program that writes on the terminal can write to a pipe. This is where the
convention of reading the standard input when no files are named pays off: any
program that adheres to the convention can be used in pipelines. grep, pr,
sort and we are all used that way in the pipelines above.
You can have as many programs in a pipeline as you wish:
creates a 3-column list of filenames on the line printer, and
$ who : grep mary : we -1
counts how many times Mary is logged in.
The programs in a pipeline actually run at the same time, not one after
another. This means that the programs in a pipeline can be interactive; the
kernel looks after whatever scheduling and synchronization is needed to make
it all work.
As you probably suspect by now, the shell arranges things when you ask for
a pipe; the individual programs are oblivious to the redirection. Of course,
programs have to operate sensibly if they are to be combined this way. Most
commands follow a common design, so they will fit properly into pipelines at
any position. Normally a command invocation looks like
command optional-arguments optional-filenames
If no filenames are given, the command reads its standard input, which is by
default the terminal (handy for experimenting) but which can be redirected to
come from a file or a pipe. At the same time, on the output side, most commands write their output on the standard output, which is by default sent to the
terminal. But it too can be redirected to a file or a pipe.
Error messages from commands have to be handled differently, however,
or they might disappear into a file or down a pipe. So each command has a
standard error output as well, which is normally directed to your terminal.
Or, as a picture:
standard input
or files
command,
options
standard
output
standard
error
Almost all of the commands we have talked about so far fit this model; the
only exceptions are commands like date and who that read no input, and a
few like crop and diff that have a fixed number of file inputs. (But look at
the '-' option on these.)
Exercise 1-7. Explain the difference between
$ who I sort
and
$ who >sort
o
Processes
The shell does quite a few things besides setting up pipes. Let us turn
briefly to the basics of running more than one program at a time, since we
have already seen a bit of that with pipes. For example, you can run two programs with one command line by separating the commands with a semicolon;
the shell recognizes the semicolon and breaks the line into two commands:
$ date;
Tue Sep
ken
dmr
rob
bwk
jj
you
ber
$
who
27 01:03:17 EDT
ttyO Sep 27
tty1 Sep 26
tty2 Sep 26
tty3 Sep 27
tty4 Sep 26
tty5 Sep 26
tty7 Sep 26
1983
00:43
23:45
23:59
00:06
23:31
23:04
23:34
Both commands are executed (in sequence) before the shell returns with a
prompt character.
You can also have more than one program running simultaneously if you
wish. For example, suppose you want to do something time-consuming like
counting the words in your book, but you don't want to wait for we to finish
before you start something else. Then you can say
$ we eh* >we.out &
6944
$
Process-id printed by the shell
The ampersand &. at the end of a command line says to the shell "start this
command running, then take further commands from the terminal immediately," that is, don't wait for it to complete. Thus the command win begin,
but you can do something else while it's running. Directing the output into the
file we 11 out keeps it from interfering with whatever you're doing at the same
time.
An instance of a running program is called a process. The number printed
by the shell for a command initiated with &. is called the process-id; you can
use it in other commands to refer to a specific running program.
It's important to distinguish between programs and processes. we is a program; each time you run the program wc, that creates a new process. If
several instances of the same program are running at the same time, each is a
separate process with a different process-id.
If a pipeline is initiated with &., as in
$ pr ch*
6951
$
CHAPTER 1
/ lpr &
Process-id of lpr
the processes in it are all started at once - the &. applies to the whole pipeline.
Only one process-id is printed, however, for the last process in the sequence.
The command
$ wait
waits until an processes initiated with &. have finished. If it doesn't return
immediately, you have commands still running. You can interrupt wait with
DELETE.
You can use the process-id printed by the shell to stop a process initiated
with &.:
$ kill 6944
If you forget the process-id, you can use the command ps to tell you abC'ut
everything you have running. If you are desperate, kill 0 will kill all your
processes except your login shell. And if you're curious about what other users
are doing, ps -ag will tell you about all processes that are currently running.
Here is some sample output:
$ ps -ag
PID TTY
36 co
6423 5
6704 1
6722 1
4430 2
6612 7
6628 7
6843 2
6949 4
6952 5
6951 5
6959 5
6844 1
$
TIME CMD
6:29 /etc/cron
0:02 -sh
0:04 -sh
0:12 vi paper
0:03 -sh
0:03 -sh
1:13 rogue
0:02 write dmr
0:01 login bimmler
0:08 pr ch1.1 ch1.2 ch1.3 ch1.4
0:03 lpr
0:02 ps -ag
0:02 write rob
PID is the process-id; TTY is the terminal associated with the process (as in
who); TIME is the processor time used in minutes and seconds; and the rest is
the command being run. ps is one of those commands that is different on different versions of the system, so your output may not be formatted like this.
Even the arguments may be different - see the manual page ps( 1).
Processes have the same sort of hierarchical structure that files do: each
process has a parent, and may well have children. Your shell was created by a
process associated with whatever terminal line connects you to the system. As
you run commands, those processes are the direct children of your shell. If
you run a program from within one of those, for example with the ! command
to escape from ed, that creates its own child process which is thus a grandchild
of the shell.
Sometimes a process takes so long that you would like to start it running,
then turn off the terminal and go home without waiting for it to finish. But if
you turn off your terminal or break your connection, the process will normally
be killed even if you used &. The command nohup ("no hangup") was
created to deal with this situation: if you say
$ nohup command &.
the command will continue to run if you log out. Any output from the command is saved in a file called nohup. out. There is no way to nohup a command retroactively.
If your process will take a lot of processor resources, it is kind to those who
share your system to run your job with lower than normal priority; this is done
by another program called nice:
$ ni ce expensive-command &.
nohup automatically calls nice, because if you're going to log out you can
afford to have the command take a little longer.
Finally, you can simply tell the system to start your process at some wee
hour of the morning when normal people are asleep, not computing. The command is called a t( 1) :
$ at time
whatever commands
you want ...
ctl-d
$
This is the typical usage, but of course the commands could come from a file:
$ at 3am <file
$
Times can be written in 24-hour style like 2 1 30, or 12-hour style like 930 pm.
Tailoring the environment
One of the virtues of the UNIX system is that there are several ways to bring
it closer to your personal taste or the conventions of your local computing
environment. For example, we mentioned earlier the problem of different
standards for the erase and line kill characters, which by default are usually #
and @. You can change these any time you want with
$ stty erase e kill k
where e is whatever character you want for erase and k is for line kill. But it's
a bother to have to type this every tirrle you log in.
The shell comes to the rescue. If there is a file named .. profile in your
login directory, the shell will execute the commands in it when you log in,
before printing the first prompt. So you can put commands into .. profile to
set up your environment as you like it, and they will be executed every time
you log in.
The first thing most people put in their .. profile is
stty erase ...
We're using +- here so you can see it, but you could put a literal backspace in
your .. profile. stty also understands the notation AX for etl-x, so you can
get the same effect with
stty erase 'J'.h'
because etl-h is backspace. (The A character is an obsolete synonym for the
pipe operator :, so you must protect it with quotes.)
If your terminal doesn't have sensible tab stops, you can add -tabs to the
stty line:
stty erase 'J'.h' -tabs
If you like to see how busy the system is when you log in, add
who : we -1
to count the users. If there's a news service, you can add news. Some people
like a fortune cookie:
/usr/games/fortune
After a while you may decide that it is taking too long to log in, and cut your
.. prof i 1 e back to the bare necessities.
Some of the properties of the shell are actually controlled by so-called shell
variables, with values that you can access and set yourself. For example, the
prompt string, which we have been showing as $, is actually stored in a shell
variable called PS 1, and you can set it to anything you like, like this:
PS1='Yes dear? '
The quotes are necessary since there are spaces in the prompt string. Spaces
are not permitted around the = in this construction.
The shell also treats the variables HOME and MAl L specially. HOME is the
name of your home directory; it is normally set properly without having to be
in .. profile. The variable MAIL names the standard file where your mail is
kept. If you define it for the shell, you will be notified after each command if
new mail has arrived:t
t This is implemented badly in the shell. Looking at the file after every command adds perceptibly
to the system load. Also, if you are working in an editor for a long time you won't learn about
MAIL=/usr/spool/mail/you
(The mail file may be different on your system; /usr /mail/you is also common.)
Probably the most useful shell variable is the one that controls where the
shell looks for commands. Recall that when you type the name of a command,
the shell normally looks for it first in the current directory, then in /bin, and
then in /usr /bin. This sequence of directories is called the search path, and
is stored in a shell variable called PATH. If the default search path isn't what
you want, you can change it, again usually in your .. profile. For example,
this line sets the path to the standard one plus /usr /games:
PATH=.:lbin:/usr/bin:/usr/games
One way...
The syntax is a bit strange: a sequence of directory names separated by colons.
Remenlber that '.. ' is the current directory. You can omit the '.. '; a null component in PATH means the current directory.
An alternate way to set PATH in this specific case is simply to augment the
previous value:
PATH=$PATH:/usr/games
. .. Another way
You can obtain the value of any shell variable by prefixing its name with a $.
In the example above, the expression $PATH retrieves the current value, to
which the new part is added, and the result is assigned back to PATH. You can
verify this with echo:
$ echo PATH is $PATH
PATH is :/bin:/usr/bin:/usr/games
$ echo $HOME Your login directory
/usr/you
$
If you have some of your own commands, you might want to collect them
in a directory of your own and add that to your search path as well. In that
case, your PATH might look like this:
PATH=:$HOME/bin:/bin:/usr/bin:/usr/games
We'll talk about writing your own commands in Chapter 3.
Another variable, often used by text editors fancier than ed, is TERM,
which names the kind of terminal you are using. That information may make
it possible for programs to manage your screen more effectively. Thus you
might add something like
new mail because you aren't running new commands with your login shell A better design is to
look every few minutes, instead of after every command. Chapters 5 and 7 show how to implement this kind of mail checker. A third possibility, not available to everyone, is to have the mail
program notify you itself: it certainly knows when mail comes for you.
TERM=adm3
to your ..profile file.
It is also possible to use variables for abbreviation. If you find yourself frequently referring to some directory with a long name, it might be worthwhile
adding a line like
d = / horribly / long / directory / name
to your profile, so that you can say things like
$ cd $d
Personal variables like d are conventionally spelled in lower case to distinguish
them from those used by the shell itself, like PATH.
Finally, it's necessary to tell the shell that you intend to use the variables in
other programs; this is done with the command export, to which we will
return in Chapter 3:
export MAIL PATH TERM
To summarize, here is what a typical" profile file might look like:
$ cat _profile
stty erase 'h' -tabs
MAIL=/usr/spoo1/mai1/you
PATH=:$HOME/bin:/bin:/usr/bin:/usr/games
TERM=adm3
b=$HOME/book
export MAIL PATH TERM b
date
who : we -1
$
We have by no means exhausted the services that the shell provides. One
of the most useful is that you can create your own commands by packaging
existing commands into a file to be processed by the shell. It is remarkable
how much can be achieved by this fundamentally simple mechanism. Our discussion of it begins in Chapter 3.

